{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in ./opt/homebrew/lib/python3.10/site-packages (1.2.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m26.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/opt/homebrew/opt/python@3.10/bin/python3.10 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pandas in ./opt/homebrew/lib/python3.10/site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy>=1.22.4 in ./opt/homebrew/lib/python3.10/site-packages (from pandas) (2.2.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./Users/landon/Library/Python/3.10/lib/python/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./opt/homebrew/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./opt/homebrew/lib/python3.10/site-packages (from pandas) (2025.3)\n",
      "Requirement already satisfied: six>=1.5 in ./Users/landon/Library/Python/3.10/lib/python/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m26.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/opt/homebrew/opt/python@3.10/bin/python3.10 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting camel-tools\n",
      "  Using cached camel_tools-1.5.7-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting future (from camel-tools)\n",
      "  Using cached future-1.0.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: six in ./Users/landon/Library/Python/3.10/lib/python/site-packages (from camel-tools) (1.17.0)\n",
      "Collecting docopt (from camel-tools)\n",
      "  Using cached docopt-0.6.2-py2.py3-none-any.whl\n",
      "Collecting cachetools<=6.0.0 (from camel-tools)\n",
      "  Using cached cachetools-6.0.0-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting numpy<2 (from camel-tools)\n",
      "  Using cached numpy-1.26.4-cp310-cp310-macosx_11_0_arm64.whl.metadata (61 kB)\n",
      "Collecting scipy (from camel-tools)\n",
      "  Using cached scipy-1.15.3-cp310-cp310-macosx_14_0_arm64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: pandas in ./opt/homebrew/lib/python3.10/site-packages (from camel-tools) (2.3.3)\n",
      "Collecting scikit-learn (from camel-tools)\n",
      "  Using cached scikit_learn-1.7.2-cp310-cp310-macosx_12_0_arm64.whl.metadata (11 kB)\n",
      "Collecting dill (from camel-tools)\n",
      "  Using cached dill-0.4.1-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting torch>=2.0 (from camel-tools)\n",
      "  Using cached torch-2.10.0-1-cp310-none-macosx_11_0_arm64.whl.metadata (31 kB)\n",
      "Collecting transformers<4.44.0,>=4.0 (from camel-tools)\n",
      "  Using cached transformers-4.43.4-py3-none-any.whl.metadata (43 kB)\n",
      "Collecting editdistance (from camel-tools)\n",
      "  Using cached editdistance-0.8.1-cp310-cp310-macosx_11_0_arm64.whl.metadata (3.9 kB)\n",
      "Collecting requests (from camel-tools)\n",
      "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting emoji (from camel-tools)\n",
      "  Using cached emoji-2.15.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting pyrsistent (from camel-tools)\n",
      "  Using cached pyrsistent-0.20.0-cp310-cp310-macosx_10_9_universal2.whl.metadata (27 kB)\n",
      "Collecting tabulate (from camel-tools)\n",
      "  Using cached tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
      "Collecting tqdm (from camel-tools)\n",
      "  Using cached tqdm-4.67.3-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting muddler (from camel-tools)\n",
      "  Using cached muddler-0.1.3-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting camel-kenlm<=2025.09.16 (from camel-tools)\n",
      "  Using cached camel_kenlm-2025.9.16-cp310-cp310-macosx_15_0_arm64.whl.metadata (251 bytes)\n",
      "Collecting filelock (from transformers<4.44.0,>=4.0->camel-tools)\n",
      "  Using cached filelock-3.20.3-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.23.2 (from transformers<4.44.0,>=4.0->camel-tools)\n",
      "  Using cached huggingface_hub-0.36.2-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in ./Users/landon/Library/Python/3.10/lib/python/site-packages (from transformers<4.44.0,>=4.0->camel-tools) (26.0)\n",
      "Collecting pyyaml>=5.1 (from transformers<4.44.0,>=4.0->camel-tools)\n",
      "  Using cached pyyaml-6.0.3-cp310-cp310-macosx_11_0_arm64.whl.metadata (2.4 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers<4.44.0,>=4.0->camel-tools)\n",
      "  Using cached regex-2026.1.15-cp310-cp310-macosx_11_0_arm64.whl.metadata (40 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers<4.44.0,>=4.0->camel-tools)\n",
      "  Using cached safetensors-0.7.0-cp38-abi3-macosx_11_0_arm64.whl.metadata (4.1 kB)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers<4.44.0,>=4.0->camel-tools)\n",
      "  Using cached tokenizers-0.19.1-cp310-cp310-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.23.2->transformers<4.44.0,>=4.0->camel-tools)\n",
      "  Using cached fsspec-2026.2.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub<1.0,>=0.23.2->transformers<4.44.0,>=4.0->camel-tools)\n",
      "  Using cached hf_xet-1.2.0-cp37-abi3-macosx_11_0_arm64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./Users/landon/Library/Python/3.10/lib/python/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers<4.44.0,>=4.0->camel-tools) (4.15.0)\n",
      "Collecting sympy>=1.13.3 (from torch>=2.0->camel-tools)\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx>=2.5.1 (from torch>=2.0->camel-tools)\n",
      "  Using cached networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting jinja2 (from torch>=2.0->camel-tools)\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch>=2.0->camel-tools)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch>=2.0->camel-tools)\n",
      "  Using cached markupsafe-3.0.3-cp310-cp310-macosx_11_0_arm64.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./Users/landon/Library/Python/3.10/lib/python/site-packages (from pandas->camel-tools) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./opt/homebrew/lib/python3.10/site-packages (from pandas->camel-tools) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./opt/homebrew/lib/python3.10/site-packages (from pandas->camel-tools) (2025.3)\n",
      "Collecting charset_normalizer<4,>=2 (from requests->camel-tools)\n",
      "  Using cached charset_normalizer-3.4.4-cp310-cp310-macosx_10_9_universal2.whl.metadata (37 kB)\n",
      "Collecting idna<4,>=2.5 (from requests->camel-tools)\n",
      "  Using cached idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->camel-tools)\n",
      "  Using cached urllib3-2.6.3-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests->camel-tools)\n",
      "  Using cached certifi-2026.1.4-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn->camel-tools)\n",
      "  Using cached joblib-1.5.3-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn->camel-tools)\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Using cached camel_tools-1.5.7-py3-none-any.whl (124 kB)\n",
      "Using cached cachetools-6.0.0-py3-none-any.whl (10 kB)\n",
      "Using cached camel_kenlm-2025.9.16-cp310-cp310-macosx_15_0_arm64.whl (527 kB)\n",
      "Using cached numpy-1.26.4-cp310-cp310-macosx_11_0_arm64.whl (14.0 MB)\n",
      "Using cached transformers-4.43.4-py3-none-any.whl (9.4 MB)\n",
      "Using cached huggingface_hub-0.36.2-py3-none-any.whl (566 kB)\n",
      "Using cached hf_xet-1.2.0-cp37-abi3-macosx_11_0_arm64.whl (2.7 MB)\n",
      "Using cached tokenizers-0.19.1-cp310-cp310-macosx_11_0_arm64.whl (2.4 MB)\n",
      "Using cached fsspec-2026.2.0-py3-none-any.whl (202 kB)\n",
      "Using cached pyyaml-6.0.3-cp310-cp310-macosx_11_0_arm64.whl (174 kB)\n",
      "Using cached regex-2026.1.15-cp310-cp310-macosx_11_0_arm64.whl (288 kB)\n",
      "Using cached safetensors-0.7.0-cp38-abi3-macosx_11_0_arm64.whl (447 kB)\n",
      "Using cached torch-2.10.0-1-cp310-none-macosx_11_0_arm64.whl (79.4 MB)\n",
      "Using cached networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Using cached tqdm-4.67.3-py3-none-any.whl (78 kB)\n",
      "Using cached dill-0.4.1-py3-none-any.whl (120 kB)\n",
      "Using cached editdistance-0.8.1-cp310-cp310-macosx_11_0_arm64.whl (79 kB)\n",
      "Using cached emoji-2.15.0-py3-none-any.whl (608 kB)\n",
      "Using cached filelock-3.20.3-py3-none-any.whl (16 kB)\n",
      "Using cached future-1.0.0-py3-none-any.whl (491 kB)\n",
      "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Using cached markupsafe-3.0.3-cp310-cp310-macosx_11_0_arm64.whl (12 kB)\n",
      "Using cached muddler-0.1.3-py3-none-any.whl (16 kB)\n",
      "Using cached pyrsistent-0.20.0-cp310-cp310-macosx_10_9_universal2.whl (83 kB)\n",
      "Using cached requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Using cached charset_normalizer-3.4.4-cp310-cp310-macosx_10_9_universal2.whl (209 kB)\n",
      "Using cached idna-3.11-py3-none-any.whl (71 kB)\n",
      "Using cached urllib3-2.6.3-py3-none-any.whl (131 kB)\n",
      "Using cached certifi-2026.1.4-py3-none-any.whl (152 kB)\n",
      "Using cached scikit_learn-1.7.2-cp310-cp310-macosx_12_0_arm64.whl (8.7 MB)\n",
      "Using cached joblib-1.5.3-py3-none-any.whl (309 kB)\n",
      "Using cached scipy-1.15.3-cp310-cp310-macosx_14_0_arm64.whl (22.4 MB)\n",
      "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Using cached tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Installing collected packages: mpmath, docopt, camel-kenlm, urllib3, tqdm, threadpoolctl, tabulate, sympy, safetensors, regex, pyyaml, pyrsistent, numpy, networkx, muddler, MarkupSafe, joblib, idna, hf-xet, future, fsspec, filelock, emoji, editdistance, dill, charset_normalizer, certifi, cachetools, scipy, requests, jinja2, torch, scikit-learn, huggingface-hub, tokenizers, transformers, camel-tools\n",
      "\u001b[2K  Attempting uninstall: numpy\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 7/37\u001b[0m [sympy]3]\n",
      "\u001b[2K    Found existing installation: numpy 2.2.6━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 7/37\u001b[0m [sympy]\n",
      "\u001b[2K    Uninstalling numpy-2.2.6:╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12/37\u001b[0m [numpy]\n",
      "\u001b[2K      Successfully uninstalled numpy-2.2.6━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12/37\u001b[0m [numpy]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37/37\u001b[0m [camel-tools]\u001b[0m [transformers]ub]\n",
      "\u001b[1A\u001b[2KSuccessfully installed MarkupSafe-3.0.3 cachetools-6.0.0 camel-kenlm-2025.9.16 camel-tools-1.5.7 certifi-2026.1.4 charset_normalizer-3.4.4 dill-0.4.1 docopt-0.6.2 editdistance-0.8.1 emoji-2.15.0 filelock-3.20.3 fsspec-2026.2.0 future-1.0.0 hf-xet-1.2.0 huggingface-hub-0.36.2 idna-3.11 jinja2-3.1.6 joblib-1.5.3 mpmath-1.3.0 muddler-0.1.3 networkx-3.4.2 numpy-1.26.4 pyrsistent-0.20.0 pyyaml-6.0.3 regex-2026.1.15 requests-2.32.5 safetensors-0.7.0 scikit-learn-1.7.2 scipy-1.15.3 sympy-1.14.0 tabulate-0.9.0 threadpoolctl-3.6.0 tokenizers-0.19.1 torch-2.10.0 tqdm-4.67.3 transformers-4.43.4 urllib3-2.6.3\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m26.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/opt/homebrew/opt/python@3.10/bin/python3.10 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting google-generativeai\n",
      "  Using cached google_generativeai-0.8.6-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting google-ai-generativelanguage==0.6.15 (from google-generativeai)\n",
      "  Using cached google_ai_generativelanguage-0.6.15-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting google-api-core (from google-generativeai)\n",
      "  Using cached google_api_core-2.29.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting google-api-python-client (from google-generativeai)\n",
      "  Using cached google_api_python_client-2.189.0-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting google-auth>=2.15.0 (from google-generativeai)\n",
      "  Using cached google_auth-2.48.0-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting protobuf (from google-generativeai)\n",
      "  Using cached protobuf-6.33.5-cp39-abi3-macosx_10_9_universal2.whl.metadata (593 bytes)\n",
      "Collecting pydantic (from google-generativeai)\n",
      "  Using cached pydantic-2.12.5-py3-none-any.whl.metadata (90 kB)\n",
      "Requirement already satisfied: tqdm in ./opt/homebrew/lib/python3.10/site-packages (from google-generativeai) (4.67.3)\n",
      "Requirement already satisfied: typing-extensions in ./Users/landon/Library/Python/3.10/lib/python/site-packages (from google-generativeai) (4.15.0)\n",
      "Collecting google-auth>=2.15.0 (from google-generativeai)\n",
      "  Using cached google_auth-2.49.0.dev0-py3-none-any.whl.metadata (6.0 kB)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-ai-generativelanguage==0.6.15->google-generativeai)\n",
      "  Using cached proto_plus-1.27.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting protobuf (from google-generativeai)\n",
      "  Using cached protobuf-5.29.6-cp38-abi3-macosx_10_9_universal2.whl.metadata (592 bytes)\n",
      "Collecting googleapis-common-protos<2.0.0,>=1.56.2 (from google-api-core->google-generativeai)\n",
      "  Using cached googleapis_common_protos-1.72.0-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in ./opt/homebrew/lib/python3.10/site-packages (from google-api-core->google-generativeai) (2.32.5)\n",
      "Collecting grpcio<2.0.0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai)\n",
      "  Downloading grpcio-1.78.0-cp310-cp310-macosx_11_0_universal2.whl.metadata (3.8 kB)\n",
      "Collecting grpcio-status<2.0.0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai)\n",
      "  Using cached grpcio_status-1.78.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth>=2.15.0->google-generativeai)\n",
      "  Using cached pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting cryptography>=38.0.3 (from google-auth>=2.15.0->google-generativeai)\n",
      "  Downloading cryptography-46.0.4-cp38-abi3-macosx_10_9_universal2.whl.metadata (5.7 kB)\n",
      "INFO: pip is looking at multiple versions of grpcio-status to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting grpcio-status<2.0.0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai)\n",
      "  Using cached grpcio_status-1.76.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Using cached grpcio_status-1.75.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Using cached grpcio_status-1.75.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Using cached grpcio_status-1.74.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Using cached grpcio_status-1.73.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Using cached grpcio_status-1.73.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Using cached grpcio_status-1.72.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "INFO: pip is still looking at multiple versions of grpcio-status to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached grpcio_status-1.72.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Using cached grpcio_status-1.71.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./opt/homebrew/lib/python3.10/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./opt/homebrew/lib/python3.10/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./opt/homebrew/lib/python3.10/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.6.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./opt/homebrew/lib/python3.10/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2026.1.4)\n",
      "Collecting cffi>=2.0.0 (from cryptography>=38.0.3->google-auth>=2.15.0->google-generativeai)\n",
      "  Downloading cffi-2.0.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (2.6 kB)\n",
      "Collecting pycparser (from cffi>=2.0.0->cryptography>=38.0.3->google-auth>=2.15.0->google-generativeai)\n",
      "  Using cached pycparser-3.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting pyasn1<0.7.0,>=0.6.1 (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai)\n",
      "  Using cached pyasn1-0.6.2-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting httplib2<1.0.0,>=0.19.0 (from google-api-python-client->google-generativeai)\n",
      "  Using cached httplib2-0.31.2-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting google-auth-httplib2<1.0.0,>=0.2.0 (from google-api-python-client->google-generativeai)\n",
      "  Using cached google_auth_httplib2-0.3.0-py3-none-any.whl.metadata (3.1 kB)\n",
      "Collecting uritemplate<5,>=3.0.1 (from google-api-python-client->google-generativeai)\n",
      "  Using cached uritemplate-4.2.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting pyparsing<4,>=3.1 (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai)\n",
      "  Downloading pyparsing-3.3.2-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic->google-generativeai)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.41.5 (from pydantic->google-generativeai)\n",
      "  Using cached pydantic_core-2.41.5-cp310-cp310-macosx_11_0_arm64.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspection>=0.4.2 (from pydantic->google-generativeai)\n",
      "  Using cached typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Using cached google_generativeai-0.8.6-py3-none-any.whl (155 kB)\n",
      "Using cached google_ai_generativelanguage-0.6.15-py3-none-any.whl (1.3 MB)\n",
      "Using cached google_api_core-2.29.0-py3-none-any.whl (173 kB)\n",
      "Using cached google_auth-2.49.0.dev0-py3-none-any.whl (236 kB)\n",
      "Using cached googleapis_common_protos-1.72.0-py3-none-any.whl (297 kB)\n",
      "Downloading grpcio-1.78.0-cp310-cp310-macosx_11_0_universal2.whl (11.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0mm0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached grpcio_status-1.71.2-py3-none-any.whl (14 kB)\n",
      "Using cached proto_plus-1.27.1-py3-none-any.whl (50 kB)\n",
      "Using cached protobuf-5.29.6-cp38-abi3-macosx_10_9_universal2.whl (418 kB)\n",
      "Downloading cryptography-46.0.4-cp38-abi3-macosx_10_9_universal2.whl (7.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading cffi-2.0.0-cp310-cp310-macosx_11_0_arm64.whl (180 kB)\n",
      "Using cached pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
      "Using cached pyasn1-0.6.2-py3-none-any.whl (83 kB)\n",
      "Using cached google_api_python_client-2.189.0-py3-none-any.whl (14.5 MB)\n",
      "Using cached google_auth_httplib2-0.3.0-py3-none-any.whl (9.5 kB)\n",
      "Using cached httplib2-0.31.2-py3-none-any.whl (91 kB)\n",
      "Downloading pyparsing-3.3.2-py3-none-any.whl (122 kB)\n",
      "Using cached uritemplate-4.2.0-py3-none-any.whl (11 kB)\n",
      "Using cached pycparser-3.0-py3-none-any.whl (48 kB)\n",
      "Using cached pydantic-2.12.5-py3-none-any.whl (463 kB)\n",
      "Using cached pydantic_core-2.41.5-cp310-cp310-macosx_11_0_arm64.whl (1.9 MB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: uritemplate, typing-inspection, pyparsing, pydantic-core, pycparser, pyasn1, protobuf, grpcio, annotated-types, pydantic, pyasn1-modules, proto-plus, httplib2, googleapis-common-protos, cffi, grpcio-status, cryptography, google-auth, google-auth-httplib2, google-api-core, google-api-python-client, google-ai-generativelanguage, google-generativeai\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23/23\u001b[0m [google-generativeai]ogle-ai-generativelanguage]\n",
      "\u001b[1A\u001b[2KSuccessfully installed annotated-types-0.7.0 cffi-2.0.0 cryptography-46.0.4 google-ai-generativelanguage-0.6.15 google-api-core-2.29.0 google-api-python-client-2.189.0 google-auth-2.49.0.dev0 google-auth-httplib2-0.3.0 google-generativeai-0.8.6 googleapis-common-protos-1.72.0 grpcio-1.78.0 grpcio-status-1.71.2 httplib2-0.31.2 proto-plus-1.27.1 protobuf-5.29.6 pyasn1-0.6.2 pyasn1-modules-0.4.2 pycparser-3.0 pydantic-2.12.5 pydantic-core-2.41.5 pyparsing-3.3.2 typing-inspection-0.4.2 uritemplate-4.2.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m26.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/opt/homebrew/opt/python@3.10/bin/python3.10 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting streamlit\n",
      "  Using cached streamlit-1.54.0-py3-none-any.whl.metadata (9.8 kB)\n",
      "Collecting altair!=5.4.0,!=5.4.1,<7,>=4.0 (from streamlit)\n",
      "  Using cached altair-6.0.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting blinker<2,>=1.5.0 (from streamlit)\n",
      "  Using cached blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: cachetools<7,>=5.5 in ./opt/homebrew/lib/python3.10/site-packages (from streamlit) (6.0.0)\n",
      "Collecting click<9,>=7.0 (from streamlit)\n",
      "  Using cached click-8.3.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit)\n",
      "  Using cached gitpython-3.1.46-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy<3,>=1.23 in ./opt/homebrew/lib/python3.10/site-packages (from streamlit) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20 in ./Users/landon/Library/Python/3.10/lib/python/site-packages (from streamlit) (26.0)\n",
      "Requirement already satisfied: pandas<3,>=1.4.0 in ./opt/homebrew/lib/python3.10/site-packages (from streamlit) (2.3.3)\n",
      "Collecting pillow<13,>=7.1.0 (from streamlit)\n",
      "  Using cached pillow-12.1.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (8.8 kB)\n",
      "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
      "  Using cached pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: protobuf<7,>=3.20 in ./opt/homebrew/lib/python3.10/site-packages (from streamlit) (5.29.6)\n",
      "Collecting pyarrow>=7.0 (from streamlit)\n",
      "  Downloading pyarrow-23.0.0-cp310-cp310-macosx_12_0_arm64.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: requests<3,>=2.27 in ./opt/homebrew/lib/python3.10/site-packages (from streamlit) (2.32.5)\n",
      "Collecting tenacity<10,>=8.1.0 (from streamlit)\n",
      "  Using cached tenacity-9.1.4-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting toml<2,>=0.10.1 (from streamlit)\n",
      "  Using cached toml-0.10.2-py2.py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in ./Users/landon/Library/Python/3.10/lib/python/site-packages (from streamlit) (6.5.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10.0 in ./Users/landon/Library/Python/3.10/lib/python/site-packages (from streamlit) (4.15.0)\n",
      "Requirement already satisfied: jinja2 in ./opt/homebrew/lib/python3.10/site-packages (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (3.1.6)\n",
      "Collecting jsonschema>=3.0 (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit)\n",
      "  Using cached jsonschema-4.26.0-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting narwhals>=1.27.1 (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit)\n",
      "  Using cached narwhals-2.16.0-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
      "  Using cached gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
      "  Using cached smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./Users/landon/Library/Python/3.10/lib/python/site-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./opt/homebrew/lib/python3.10/site-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./opt/homebrew/lib/python3.10/site-packages (from pandas<3,>=1.4.0->streamlit) (2025.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./opt/homebrew/lib/python3.10/site-packages (from requests<3,>=2.27->streamlit) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./opt/homebrew/lib/python3.10/site-packages (from requests<3,>=2.27->streamlit) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./opt/homebrew/lib/python3.10/site-packages (from requests<3,>=2.27->streamlit) (2.6.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./opt/homebrew/lib/python3.10/site-packages (from requests<3,>=2.27->streamlit) (2026.1.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./opt/homebrew/lib/python3.10/site-packages (from jinja2->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (3.0.3)\n",
      "Collecting attrs>=22.2.0 (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit)\n",
      "  Using cached attrs-25.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit)\n",
      "  Using cached jsonschema_specifications-2025.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit)\n",
      "  Using cached referencing-0.37.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rpds-py>=0.25.0 (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit)\n",
      "  Downloading rpds_py-0.30.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: six>=1.5 in ./Users/landon/Library/Python/3.10/lib/python/site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
      "Using cached streamlit-1.54.0-py3-none-any.whl (9.1 MB)\n",
      "Using cached altair-6.0.0-py3-none-any.whl (795 kB)\n",
      "Using cached blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
      "Using cached click-8.3.1-py3-none-any.whl (108 kB)\n",
      "Using cached gitpython-3.1.46-py3-none-any.whl (208 kB)\n",
      "Using cached gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
      "Using cached pillow-12.1.0-cp310-cp310-macosx_11_0_arm64.whl (4.7 MB)\n",
      "Using cached pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
      "Using cached smmap-5.0.2-py3-none-any.whl (24 kB)\n",
      "Using cached tenacity-9.1.4-py3-none-any.whl (28 kB)\n",
      "Using cached toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Using cached jsonschema-4.26.0-py3-none-any.whl (90 kB)\n",
      "Using cached attrs-25.4.0-py3-none-any.whl (67 kB)\n",
      "Using cached jsonschema_specifications-2025.9.1-py3-none-any.whl (18 kB)\n",
      "Using cached narwhals-2.16.0-py3-none-any.whl (443 kB)\n",
      "Downloading pyarrow-23.0.0-cp310-cp310-macosx_12_0_arm64.whl (34.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.3/34.3 MB\u001b[0m \u001b[31m58.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached referencing-0.37.0-py3-none-any.whl (26 kB)\n",
      "Downloading rpds_py-0.30.0-cp310-cp310-macosx_11_0_arm64.whl (359 kB)\n",
      "Installing collected packages: toml, tenacity, smmap, rpds-py, pyarrow, pillow, narwhals, click, blinker, attrs, referencing, pydeck, gitdb, jsonschema-specifications, gitpython, jsonschema, altair, streamlit\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18/18\u001b[0m [streamlit]18\u001b[0m [streamlit]\n",
      "\u001b[1A\u001b[2KSuccessfully installed altair-6.0.0 attrs-25.4.0 blinker-1.9.0 click-8.3.1 gitdb-4.0.12 gitpython-3.1.46 jsonschema-4.26.0 jsonschema-specifications-2025.9.1 narwhals-2.16.0 pillow-12.1.0 pyarrow-23.0.0 pydeck-0.9.1 referencing-0.37.0 rpds-py-0.30.0 smmap-5.0.2 streamlit-1.54.0 tenacity-9.1.4 toml-0.10.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m26.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/opt/homebrew/opt/python@3.10/bin/python3.10 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pandas in ./opt/homebrew/lib/python3.10/site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy>=1.22.4 in ./opt/homebrew/lib/python3.10/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./Users/landon/Library/Python/3.10/lib/python/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./opt/homebrew/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./opt/homebrew/lib/python3.10/site-packages (from pandas) (2025.3)\n",
      "Requirement already satisfied: six>=1.5 in ./Users/landon/Library/Python/3.10/lib/python/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m26.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/opt/homebrew/opt/python@3.10/bin/python3.10 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: python-dotenv in ./opt/homebrew/lib/python3.10/site-packages (1.2.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m26.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/opt/homebrew/opt/python@3.10/bin/python3.10 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install python-dotenv\n",
    "%pip install pandas\n",
    "%pip install camel-tools\n",
    "%pip install google-generativeai\n",
    "%pip install streamlit\n",
    "%pip install pandas\n",
    "%pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/google/api_core/_python_version_support.py:275: FutureWarning: You are using a Python version (3.10.19) which Google will stop supporting in new releases of google.api_core once it reaches its end of life (2026-10-04). Please upgrade to the latest Python version, or at least Python 3.11, to continue receiving updates for google.api_core past that date.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅All imports successful\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/var/folders/mp/jwvmd31j30ngx7dj9xnpykkc0000gn/T/ipykernel_18368/3916141819.py:14: FutureWarning: \n",
      "\n",
      "All support for the `google.generativeai` package has ended. It will no longer be receiving \n",
      "updates or bug fixes. Please switch to the `google.genai` package as soon as possible.\n",
      "See README for more details:\n",
      "\n",
      "https://github.com/google-gemini/deprecated-generative-ai-python/blob/main/README.md\n",
      "\n",
      "  import google.generativeai as genai\n"
     ]
    }
   ],
   "source": [
    "#Import libraries\n",
    "import os\n",
    "from typing import List, Dict, Optional\n",
    "import json\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "#Arabic NLP\n",
    "from camel_tools.tokenizers.word import simple_word_tokenize\n",
    "from camel_tools.morphology.database import MorphologyDB\n",
    "from camel_tools.morphology.analyzer import Analyzer\n",
    "\n",
    "# LLM API (choose one)\n",
    "import google.generativeai as genai\n",
    "\n",
    "print(\"✅All imports successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠ Warning: API key not found. Set it in .env file or manually below:\n"
     ]
    }
   ],
   "source": [
    "#Environemnt Setup\n",
    "\n",
    "API_KEY = os.getenv('GEMINI_API_KEY')\n",
    "if API_KEY:\n",
    "    print(\"✅API key loaded successfully\")\n",
    "    print(f\"  Key starts with: {API_KEY[:10]}...\")\n",
    "else:\n",
    "    print(\"⚠ Warning: API key not found. Set it in .env file or manually below:\")\n",
    "    API_KEY = \"AIzaSyCqKFvTQ9lIBpKjYdceYJEKjauALKL55zE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Gemini client initialized with model: gemini-2.0-flash\n"
     ]
    }
   ],
   "source": [
    "genai.configure(api_key=API_KEY)\n",
    "\n",
    "# OLD (broken - retired April 2025):\n",
    "# MODEL = \"gemini-1.5-flash\"\n",
    "\n",
    "# PICK ONE of these current options:\n",
    "MODEL = \"gemini-2.0-flash\"        # ✅ Best choice - fast, cheap, very capable\n",
    "# MODEL = \"gemini-2.5-flash\"      # More powerful, slightly more expensive\n",
    "# MODEL = \"gemini-2.5-pro\"        # Most capable, most expensive\n",
    "\n",
    "client = genai.GenerativeModel(MODEL)\n",
    "print(f\"✓ Gemini client initialized with model: {MODEL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading morphology database...\n",
      "✓ CAMeL Tools analyzer ready\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading morphology database...\")\n",
    "db = MorphologyDB.builtin_db()\n",
    "analyzer = Analyzer(db)\n",
    "print(\"✓ CAMeL Tools analyzer ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test sentence: ذهب الولد إلى المدرسة\n",
      "Tokens: ['ذهب', 'الولد', 'إلى', 'المدرسة']\n",
      "✓ Tokenization working (4 tokens)\n"
     ]
    }
   ],
   "source": [
    "#Basic Tokenization Function\n",
    "\n",
    "def tokenize_arabic(text: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Tokenize Arabic text into words.\n",
    "    Handles both voweled and unvoweled text.\n",
    "    \"\"\"\n",
    "    tokens = simple_word_tokenize(text)\n",
    "    # Filter out empty tokens and punctuation-only tokens\n",
    "    tokens = [t for t in tokens if t.strip() and not all(c in '.,!?;:،؛' for c in t)]\n",
    "    return tokens\n",
    "\n",
    "# Test\n",
    "test_sentence = \"ذهب الولد إلى المدرسة\"\n",
    "test_tokens = tokenize_arabic(test_sentence)\n",
    "print(f\"Test sentence: {test_sentence}\")\n",
    "print(f\"Tokens: {test_tokens}\")\n",
    "print(f\"✓ Tokenization working ({len(test_tokens)} tokens)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Morphological analysis for 'الولد':\n",
      "\n",
      "  Analysis 1:\n",
      "    Vocalized: الوَلَد\n",
      "    Lemma: وَلَد\n",
      "    POS: noun\n",
      "    Gloss: the+child;son\n",
      "\n",
      "  Analysis 2:\n",
      "    Vocalized: الوَلَدَ\n",
      "    Lemma: وَلَد\n",
      "    POS: noun\n",
      "    Gloss: the+child;son+[def.acc.]\n",
      "\n",
      "  Analysis 3:\n",
      "    Vocalized: الوَلَدِ\n",
      "    Lemma: وَلَد\n",
      "    POS: noun\n",
      "    Gloss: the+child;son+[def.gen.]\n",
      "\n",
      "✓ Morphological analysis working\n"
     ]
    }
   ],
   "source": [
    "# PHASE 2 - CELL 3: Morphological Analysis Function\n",
    "\n",
    "def analyze_word_morphology(word: str, max_analyses: int = 3) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Get morphological analysis for a single Arabic word.\n",
    "    Returns top N analyses with relevant features.\n",
    "    \"\"\"\n",
    "    analyses = analyzer.analyze(word)\n",
    "    \n",
    "    results = []\n",
    "    for analysis in analyses[:max_analyses]:\n",
    "        result = {\n",
    "            'word': word,\n",
    "            'diac': analysis.get('diac', word),  # Vocalized form\n",
    "            'lex': analysis.get('lex', ''),       # Lemma/root\n",
    "            'pos': analysis.get('pos', ''),       # Part of speech\n",
    "            'gloss': analysis.get('gloss', ''),   # English gloss\n",
    "            'features': {\n",
    "                'gender': analysis.get('gen', ''),\n",
    "                'number': analysis.get('num', ''),\n",
    "                'person': analysis.get('per', ''),\n",
    "                'case': analysis.get('cas', ''),\n",
    "                'state': analysis.get('stt', ''),\n",
    "            }\n",
    "        }\n",
    "        results.append(result)\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Test\n",
    "test_word = \"الولد\"\n",
    "morphology = analyze_word_morphology(test_word)\n",
    "print(f\"\\nMorphological analysis for '{test_word}':\")\n",
    "for i, analysis in enumerate(morphology, 1):\n",
    "    print(f\"\\n  Analysis {i}:\")\n",
    "    print(f\"    Vocalized: {analysis['diac']}\")\n",
    "    print(f\"    Lemma: {analysis['lex']}\")\n",
    "    print(f\"    POS: {analysis['pos']}\")\n",
    "    print(f\"    Gloss: {analysis['gloss']}\")\n",
    "print(\"\\n✓ Morphological analysis working\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Full sentence analysis for: ذهب الولد إلى المدرسة\n",
      "\n",
      "  ذهب → ذَهَب\n",
      "  الولد → الوَلَد\n",
      "  إلى → آلِي\n",
      "  المدرسة → المُدَرِّسَة\n",
      "\n",
      "✓ Full sentence analysis working\n"
     ]
    }
   ],
   "source": [
    "#Full Sentence Analysis\n",
    "\n",
    "def analyze_sentence(sentence: str) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Analyze entire sentence: tokenize + morphology for each word.\n",
    "    \"\"\"\n",
    "    tokens = tokenize_arabic(sentence)\n",
    "    sentence_analysis = []\n",
    "    \n",
    "    for token in tokens:\n",
    "        word_data = {\n",
    "            'original': token,\n",
    "            'morphology': analyze_word_morphology(token, max_analyses=1)  \n",
    "        }\n",
    "        sentence_analysis.append(word_data)\n",
    "    \n",
    "    return sentence_analysis\n",
    "\n",
    "# Test\n",
    "test_analysis = analyze_sentence(test_sentence)\n",
    "print(f\"\\nFull sentence analysis for: {test_sentence}\\n\")\n",
    "for word_data in test_analysis:\n",
    "    print(f\"  {word_data['original']} → {word_data['morphology'][0]['diac'] if word_data['morphology'] else 'N/A'}\")\n",
    "print(\"\\n✓ Full sentence analysis working\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample prompt:\n",
      "\n",
      "أنت خبير في النحو العربي والإعراب. مهمتك تحليل الجمل العربية وتقديم إعراب مفصل لكل كلمة.\n",
      "\n",
      "You are an expert in Arabic grammar and i'rab (grammatical analysis). Your task is to analyze Arabic sentences and provide detailed grammatical parsing.\n",
      "\n",
      "For each word, provide:\n",
      "1. الإعراب (grammatical role: فاعل، مفعول به، مبتدأ، خبر، etc.)\n",
      "2. علامة الإعراب (grammatical marker: الضمة، الفتحة، الكسرة، etc.)\n",
      "3. التفاصيل الإضافية (additional details: definite/indefinite, gender, number, etc.)\n",
      "4. Brief English...\n",
      "\n",
      "✓ Prompt template working\n"
     ]
    }
   ],
   "source": [
    "# I'rab Prompt Template\n",
    "\n",
    "IRAB_SYSTEM_PROMPT = \"\"\"أنت خبير في النحو العربي والإعراب. مهمتك تحليل الجمل العربية وتقديم إعراب مفصل لكل كلمة.\n",
    "\n",
    "You are an expert in Arabic grammar and i'rab (grammatical analysis). Your task is to analyze Arabic sentences and provide detailed grammatical parsing.\n",
    "\n",
    "For each word, provide:\n",
    "1. الإعراب (grammatical role: فاعل، مفعول به، مبتدأ، خبر، etc.)\n",
    "2. علامة الإعراب (grammatical marker: الضمة، الفتحة، الكسرة، etc.)\n",
    "3. التفاصيل الإضافية (additional details: definite/indefinite, gender, number, etc.)\n",
    "4. Brief English explanation\n",
    "\n",
    "Return your analysis as a JSON array where each object represents one word.\"\"\"\n",
    "\n",
    "def create_irab_prompt(sentence: str, morphology_data: List[Dict]) -> str:\n",
    "    \"\"\"\n",
    "    Create a structured prompt for i'rab analysis.\n",
    "    Includes morphological hints from CAMeL Tools.\n",
    "    \"\"\"\n",
    "    # Format morphology data for context\n",
    "    morph_context = \"\\n\".join([\n",
    "        f\"- {word['original']}: POS={word['morphology'][0]['pos'] if word['morphology'] else 'unknown'}, \"\n",
    "        f\"Lemma={word['morphology'][0]['lex'] if word['morphology'] else 'unknown'}\"\n",
    "        for word in morphology_data\n",
    "    ])\n",
    "    \n",
    "    prompt = f\"\"\"{IRAB_SYSTEM_PROMPT}\n",
    "\n",
    "Analyze this Arabic sentence with full i'rab:\n",
    "\n",
    "Sentence: {sentence}\n",
    "\n",
    "Morphological hints from CAMeL Tools:\n",
    "{morph_context}\n",
    "\n",
    "Provide detailed i'rab for each word in JSON format:\n",
    "[{{\n",
    "  \"word\": \"الكلمة\",\n",
    "  \"irab\": \"فاعل\",\n",
    "  \"sign\": \"مرفوع وعلامة رفعه الضمة\",\n",
    "  \"details\": \"اسم معرف بأل، مذكر، مفرد\",\n",
    "  \"explanation\": \"Brief English explanation\"\n",
    "}}]\n",
    "\n",
    "Return ONLY the JSON array, no additional text.\"\"\"\n",
    "    \n",
    "    return prompt\n",
    "\n",
    "# Test prompt creation\n",
    "test_prompt = create_irab_prompt(test_sentence, test_analysis)\n",
    "print(\"Sample prompt:\\n\")\n",
    "print(test_prompt[:500] + \"...\")\n",
    "print(\"\\n✓ Prompt template working\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Gemini API function ready\n",
      "\n",
      "Ready to test with real API call in next cell...\n"
     ]
    }
   ],
   "source": [
    "#  Gemini API Call Function\n",
    "\n",
    "def get_irab_from_llm(sentence: str, morphology_data: List[Dict]) -> Dict:\n",
    "    \"\"\"\n",
    "    Send sentence to Gemini and get i'rab analysis.\n",
    "    Returns parsed JSON response.\n",
    "    \"\"\"\n",
    "    prompt = create_irab_prompt(sentence, morphology_data)\n",
    "    \n",
    "    try:\n",
    "        # Call Gemini API\n",
    "        response = client.generate_content(prompt)\n",
    "        response_text = response.text\n",
    "        \n",
    "        # Parse JSON from response\n",
    "        # Handle cases where LLM adds markdown formatting\n",
    "        response_text = response_text.strip()\n",
    "        if response_text.startswith('```json'):\n",
    "            response_text = response_text.split('```json')[1].split('```')[0].strip()\n",
    "        elif response_text.startswith('```'):\n",
    "            response_text = response_text.split('```')[1].split('```')[0].strip()\n",
    "        \n",
    "        irab_data = json.loads(response_text)\n",
    "        \n",
    "        return {\n",
    "            'success': True,\n",
    "            'data': irab_data,\n",
    "            'raw_response': response_text\n",
    "        }\n",
    "        \n",
    "    except json.JSONDecodeError as e:\n",
    "        return {\n",
    "            'success': False,\n",
    "            'error': f\"JSON parsing error: {str(e)}\",\n",
    "            'raw_response': response_text if 'response_text' in locals() else None\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'success': False,\n",
    "            'error': f\"API error: {str(e)}\",\n",
    "            'raw_response': None\n",
    "        }\n",
    "\n",
    "print(\"✓ Gemini API function ready\")\n",
    "print(\"\\nReady to test with real API call in next cell...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with sentence: ذهب الولد إلى المدرسة\n",
      "\n",
      "Calling Gemini API...\n",
      "\n",
      "✓ API call successful!\n",
      "\n",
      "I'rab Analysis:\n",
      "\n",
      "  ذهب:\n",
      "    الإعراب: فعل ماض\n",
      "    العلامة: مبني على الفتح\n",
      "    التفاصيل: فعل ماض مبني على الفتح الظاهر على آخره\n",
      "    Explanation: Past tense verb, built on the فتحة (fatha).\n",
      "\n",
      "  الولد:\n",
      "    الإعراب: فاعل\n",
      "    العلامة: مرفوع وعلامة رفعه الضمة الظاهرة\n",
      "    التفاصيل: اسم معرف بأل، مذكر، مفرد\n",
      "    Explanation: Subject, nominative, with a visible الضمة (damma).\n",
      "\n",
      "  إلى:\n",
      "    الإعراب: حرف جر\n",
      "    العلامة: مبني على السكون\n",
      "    التفاصيل: حرف جر مبني على السكون لا محل له من الإعراب\n",
      "    Explanation: Preposition, built on the السكون (sukoon), has no grammatical function on its own.\n",
      "\n",
      "  المدرسة:\n",
      "    الإعراب: اسم مجرور\n",
      "    العلامة: مجرور وعلامة جره الكسرة الظاهرة\n",
      "    التفاصيل: اسم معرف بأل، مؤنث، مفرد\n",
      "    Explanation: Object of the preposition, genitive, with a visible الكسرة (kasra).\n"
     ]
    }
   ],
   "source": [
    "# Test Gemini API (WILL USE API CREDITS)\n",
    "# Run this to test actual API connection\n",
    "\n",
    "print(f\"Testing with sentence: {test_sentence}\\n\")\n",
    "print(\"Calling Gemini API...\\n\")\n",
    "\n",
    "irab_result = get_irab_from_llm(test_sentence, test_analysis)\n",
    "\n",
    "if irab_result['success']:\n",
    "    print(\"✓ API call successful!\\n\")\n",
    "    print(\"I'rab Analysis:\")\n",
    "    for word_irab in irab_result['data']:\n",
    "        print(f\"\\n  {word_irab.get('word', 'N/A')}:\")\n",
    "        print(f\"    الإعراب: {word_irab.get('irab', 'N/A')}\")\n",
    "        print(f\"    العلامة: {word_irab.get('sign', 'N/A')}\")\n",
    "        print(f\"    التفاصيل: {word_irab.get('details', 'N/A')}\")\n",
    "        print(f\"    Explanation: {word_irab.get('explanation', 'N/A')}\")\n",
    "else:\n",
    "    print(\"✗ API call failed\")\n",
    "    print(f\"Error: {irab_result['error']}\")\n",
    "    if irab_result.get('raw_response'):\n",
    "        print(f\"\\nRaw response:\\n{irab_result['raw_response']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

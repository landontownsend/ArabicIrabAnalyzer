import streamlit as st
import os
import json
import time
import subprocess
import sys
import pandas as pd
from typing import List, Dict
from dotenv import load_dotenv
from camel_tools.tokenizers.word import simple_word_tokenize
from camel_tools.morphology.database import MorphologyDB
from camel_tools.morphology.analyzer import Analyzer
from google import genai

# â”€â”€ Page config â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(
    page_title="Arabic Irab Analyzer",
    page_icon="ğŸ“š",
    layout="wide",
    initial_sidebar_state="expanded"
)

st.markdown("""
<style>
    .stTextArea textarea {
        direction: rtl;
        font-size: 20px;
        font-family: 'Amiri', 'Traditional Arabic', serif;
    }
</style>
""", unsafe_allow_html=True)

# â”€â”€ Download CAMeL Tools data (required for Streamlit Cloud) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@st.cache_resource
def download_camel_data():
    try:
        subprocess.run(
            [sys.executable, "-m", "camel_tools.data", "download", "-y", "morphology-db-msa-r13"],
            check=False,
            capture_output=True
        )
    except Exception:
        pass

download_camel_data()

# â”€â”€ Load resources â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@st.cache_resource
def load_analyzer():
    db = MorphologyDB.builtin_db()
    return Analyzer(db)

@st.cache_resource
def load_gemini_client():
    load_dotenv()
    api_key = os.getenv("GEMINI_API_KEY")
    if not api_key:
        st.error("GEMINI_API_KEY not found. Add it to .env locally or Streamlit Secrets for deployment.")
        st.stop()
    client = genai.Client(api_key=api_key)
    return client

# â”€â”€ Core functions â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def tokenize_arabic(text):
    tokens = simple_word_tokenize(text)
    return [t for t in tokens if t.strip() and not all(c in ".,!?;:ØŒØ›" for c in t)]

def analyze_word_morphology(word, analyzer, max_analyses=1):
    analyses = analyzer.analyze(word)
    results = []
    for analysis in analyses[:max_analyses]:
        results.append({
            "word"    : word,
            "diac"    : analysis.get("diac", word),
            "lex"     : analysis.get("lex",  ""),
            "pos"     : analysis.get("pos",  ""),
            "gloss"   : analysis.get("gloss",""),
            "features": {
                "gender": analysis.get("gen", ""),
                "number": analysis.get("num", ""),
                "person": analysis.get("per", ""),
                "case"  : analysis.get("cas", ""),
                "state" : analysis.get("stt", ""),
            }
        })
    return results

def analyze_sentence(sentence, analyzer):
    tokens = tokenize_arabic(sentence)
    return [
        {"original": token, "morphology": analyze_word_morphology(token, analyzer)}
        for token in tokens
    ]

SYSTEM_PROMPT = """Ø£Ù†Øª Ø®Ø¨ÙŠØ± ÙÙŠ Ø§Ù„Ù†Ø­Ùˆ Ø§Ù„Ø¹Ø±Ø¨ÙŠ ÙˆØ§Ù„Ø¥Ø¹Ø±Ø§Ø¨.
You are an expert in Arabic grammar and irab. For each word provide:
1. Ø§Ù„Ø¥Ø¹Ø±Ø§Ø¨ (grammatical role)
2. Ø¹Ù„Ø§Ù…Ø© Ø§Ù„Ø¥Ø¹Ø±Ø§Ø¨ (grammatical marker)
3. Ø§Ù„ØªÙØ§ØµÙŠÙ„ (gender, number, definiteness)
4. A brief English explanation
Return a JSON array only, no extra text."""

def create_prompt(sentence, morphology_data):
    lines = []
    for w in morphology_data:
        pos   = w["morphology"][0]["pos"] if w["morphology"] else "?"
        lemma = w["morphology"][0]["lex"] if w["morphology"] else "?"
        orig  = w["original"]
        lines.append("- " + orig + " : POS=" + pos + ", lemma=" + lemma)
    morph_hints = "\n".join(lines)
    return (
        SYSTEM_PROMPT + "\n\n"
        "Sentence: " + sentence + "\n\n"
        "Morphology hints:\n" + morph_hints + "\n\n"
        "Return ONLY a JSON array:\n"
        "[{\"word\":\"...\",\"irab\":\"...\",\"sign\":\"...\",\"details\":\"...\",\"explanation\":\"...\"}]"
    )

def get_irab(sentence, morphology_data, client):
    prompt = create_prompt(sentence, morphology_data)
    for attempt in range(3):
        try:
            response = client.models.generate_content(
                model="gemini-2.0-flash",
                contents=prompt
            )
            text = response.text.strip()
            if text.startswith("```json"):
                text = text.split("```json")[1].split("```")[0].strip()
            elif text.startswith("```"):
                text = text.split("```")[1].split("```")[0].strip()
            return {"success": True, "data": json.loads(text)}
        except Exception as e:
            err = str(e)
            if "429" in err:
                if "PerDay" in err:
                    return {"success": False, "error": "Daily quota reached. Try again tomorrow or check billing."}
                time.sleep(60 * (attempt + 1))
            else:
                return {"success": False, "error": err}
    return {"success": False, "error": "Max retries exceeded."}

@st.cache_data(show_spinner=False)
def run_full_analysis(sentence):
    analyzer = load_analyzer()
    client   = load_gemini_client()
    morphology = analyze_sentence(sentence, analyzer)
    irab_resp  = get_irab(sentence, morphology, client)
    return {
        "original"  : sentence,
        "morphology": morphology,
        "irab"      : irab_resp.get("data", []),
        "success"   : irab_resp["success"],
        "error"     : irab_resp.get("error")
    }

def get_color(irab_type):
    colors = {
        "ÙØ§Ø¹Ù„"      : "#2e7d32",
        "Ù…ÙØ¹ÙˆÙ„ Ø¨Ù‡"  : "#1565c0",
        "Ù…Ø¨ØªØ¯Ø£"     : "#e65100",
        "Ø®Ø¨Ø±"       : "#ad1457",
        "Ù…Ø¶Ø§Ù Ø¥Ù„ÙŠÙ‡" : "#6a1b9a",
        "Ù†Ø¹Øª"       : "#00838f",
        "Ø­Ø§Ù„"       : "#f9a825",
        "ÙØ¹Ù„"       : "#4e342e",
        "Ø­Ø±Ù"       : "#546e7a",
        "Ø¸Ø±Ù"       : "#558b2f",
    }
    for key, color in colors.items():
        if key in irab_type:
            return color
    return "#37474f"

def word_card(word_data):
    color       = get_color(word_data.get("irab", ""))
    word        = word_data.get("word", "")
    irab        = word_data.get("irab", "")
    sign        = word_data.get("sign", "")
    details     = word_data.get("details", "")
    explanation = word_data.get("explanation", "")
    return (
        "<div style=\"background:#fff;border-right:6px solid " + color + ";border-radius:10px;"
        "padding:16px 20px;margin:10px 0;box-shadow:0 2px 6px rgba(0,0,0,0.08);direction:rtl;\">"
        "<div style=\"font-size:26px;font-weight:bold;color:" + color + ";margin-bottom:8px;\">" + word + "</div>"
        "<p style=\"margin:4px 0\"><strong>Ø§Ù„Ø¥Ø¹Ø±Ø§Ø¨:</strong> " + irab + "</p>"
        "<p style=\"margin:4px 0\"><strong>Ø§Ù„Ø¹Ù„Ø§Ù…Ø©:</strong> " + sign + "</p>"
        "<p style=\"margin:4px 0\"><strong>Ø§Ù„ØªÙØ§ØµÙŠÙ„:</strong> " + details + "</p>"
        "<p style=\"margin:4px 0;color:#666;font-style:italic\">" + explanation + "</p>"
        "</div>"
    )

def render_sidebar():
    with st.sidebar:
        st.markdown("## ğŸ“š Arabic Irab Analyzer")
        st.markdown("### Ù…Ø­Ù„Ù„ Ø§Ù„Ø¥Ø¹Ø±Ø§Ø¨ Ø§Ù„Ø¹Ø±Ø¨ÙŠ")
        st.markdown("---")
        st.markdown("""
        **What this tool does:**
        Paste any Arabic sentence â€” voweled or unvoweled â€”
        and get a full grammatical breakdown of every word.

        **Powered by:**
        - CAMeL Tools (morphology)
        - Gemini 2.0 Flash (irab analysis)
        """)
        st.markdown("---")
        st.markdown("### Ø£Ù…Ø«Ù„Ø© â€” Try an example")
        examples = [
            "Ø°Ù‡Ø¨ Ø§Ù„ÙˆÙ„Ø¯ Ø¥Ù„Ù‰ Ø§Ù„Ù…Ø¯Ø±Ø³Ø©",
            "Ù‚Ø±Ø£ Ø§Ù„Ø·Ø§Ù„Ø¨ Ø§Ù„ÙƒØªØ§Ø¨",
            "ÙƒØªØ¨ Ø§Ù„Ù…Ø¹Ù„Ù… Ø§Ù„Ø¯Ø±Ø³ Ø¹Ù„Ù‰ Ø§Ù„Ø³Ø¨ÙˆØ±Ø©",
            "Ø¬Ø§Ø¡ Ø§Ù„Ø±Ø¬Ù„ Ù…Ù† Ø§Ù„Ø³ÙˆÙ‚",
            "Ø¥Ù† Ø§Ù„Ù„Ù‡ ØºÙÙˆØ± Ø±Ø­ÙŠÙ…",
            "ØªÙØªØ­ Ø§Ù„Ø£Ø²Ù‡Ø§Ø± ÙÙŠ Ø§Ù„Ø±Ø¨ÙŠØ¹",
        ]
        for ex in examples:
            key = "ex_" + ex
            if st.button(ex, key=key, use_container_width=True):
                st.session_state.input_text = ex
                st.rerun()

def main():
    render_sidebar()

    st.title("ğŸ“š Arabic Irab Analyzer")
    st.markdown(
        "<div style=\"direction:rtl;font-size:22px;color:#555;\">Ù…Ø­Ù„Ù„ Ø§Ù„Ø¥Ø¹Ø±Ø§Ø¨ Ø§Ù„Ø¹Ø±Ø¨ÙŠ</div>",
        unsafe_allow_html=True
    )
    st.markdown("---")

    input_text = st.text_area(
        "Ø£Ø¯Ø®Ù„ Ø§Ù„Ø¬Ù…Ù„Ø© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© â€” Enter Arabic sentence:",
        value=st.session_state.get("input_text", ""),
        height=120,
        placeholder="Ø§ÙƒØªØ¨ Ø¬Ù…Ù„Ø© Ø¹Ø±Ø¨ÙŠØ© Ù‡Ù†Ø§...",
    )

    col1, col2, _ = st.columns([1, 1, 4])
    with col1:
        analyze = st.button("ğŸ” ØªØ­Ù„ÙŠÙ„ | Analyze", type="primary", use_container_width=True)
    with col2:
        if st.button("ğŸ—‘ï¸ Ù…Ø³Ø­ | Clear", use_container_width=True):
            st.session_state.input_text = ""
            st.rerun()

    if analyze and input_text.strip():
        with st.spinner("Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„... | Analyzing..."):
            result = run_full_analysis(input_text.strip())

        if result["success"]:
            st.success("âœ… Analysis complete | Ø§ÙƒØªÙ…Ù„ Ø§Ù„ØªØ­Ù„ÙŠÙ„")

            tab1, tab2, tab3 = st.tabs([
                "ğŸ“Š Ø§Ù„Ø¥Ø¹Ø±Ø§Ø¨ | Irab",
                "ğŸ”¤ Ø§Ù„ØµØ±Ù | Morphology",
                "ğŸ“ Raw Data"
            ])

            with tab1:
                st.markdown("#### Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Ø­ÙˆÙŠ Ø§Ù„ÙƒØ§Ù…Ù„")
                rows = []
                for w in result["irab"]:
                    rows.append({
                        "Ø§Ù„ÙƒÙ„Ù…Ø©"     : w.get("word", ""),
                        "Ø§Ù„Ø¥Ø¹Ø±Ø§Ø¨"    : w.get("irab", ""),
                        "Ø§Ù„Ø¹Ù„Ø§Ù…Ø©"    : w.get("sign", ""),
                        "Ø§Ù„ØªÙØ§ØµÙŠÙ„"   : w.get("details", ""),
                        "Explanation": w.get("explanation", "")
                    })
                st.dataframe(pd.DataFrame(rows), use_container_width=True, hide_index=True)
                st.markdown("---")
                st.markdown("#### ØªÙØµÙŠÙ„ ÙƒÙ„ ÙƒÙ„Ù…Ø©")
                for w in result["irab"]:
                    st.markdown(word_card(w), unsafe_allow_html=True)

            with tab2:
                st.markdown("#### Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµØ±ÙÙŠ")
                for word_data in result["morphology"]:
                    if word_data["morphology"]:
                        m        = word_data["morphology"][0]
                        original = word_data["original"]
                        diac     = m.get("diac", "N/A")
                        label    = original + " â† " + diac
                        with st.expander(label):
                            st.write("**Lemma:** "  + m.get("lex",   "N/A"))
                            st.write("**POS:** "    + m.get("pos",   "N/A"))
                            st.write("**Gloss:** "  + m.get("gloss", "N/A"))
                            feats = {k: v for k, v in m.get("features", {}).items() if v}
                            if feats:
                                st.write("**Features:**")
                                for k, v in feats.items():
                                    st.write("  - " + k + ": " + v)

            with tab3:
                st.json(result)

        else:
            st.error("âŒ " + str(result["error"]))

    elif analyze:
        st.warning("âš ï¸ Please enter a sentence first | Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø¥Ø¯Ø®Ø§Ù„ Ø¬Ù…Ù„Ø©")

    st.markdown("---")
    st.markdown(
        "<div style=\"text-align:center;color:#aaa;font-size:13px;\">"
        "Built with CAMeL Tools + Gemini API Â· Powered by Streamlit"
        "</div>",
        unsafe_allow_html=True
    )

if __name__ == "__main__":
    main()

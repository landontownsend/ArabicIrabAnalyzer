import streamlit as st
import os
import json
import time
import pandas as pd
from dotenv import load_dotenv
from google import genai
import pyarabic.araby as araby

# â”€â”€ Page config â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(
    page_title="Arabic Irab Analyzer",
    page_icon="ğŸ“š",
    layout="wide",
    initial_sidebar_state="expanded"
)

st.markdown("""
<style>
    .stTextArea textarea {
        direction: rtl;
        font-size: 20px;
        font-family: 'Amiri', 'Traditional Arabic', serif;
    }
</style>
""", unsafe_allow_html=True)

# â”€â”€ Load Gemini â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@st.cache_resource
def load_gemini_client():
    load_dotenv()
    api_key = os.getenv("GEMINI_API_KEY")
    if not api_key:
        st.error("GEMINI_API_KEY not found.")
        st.stop()
    return genai.Client(api_key=api_key)

# â”€â”€ PyArabic Preprocessing â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def preprocess_arabic(sentence):
    """
    Extract rich linguistic features from Arabic text using PyArabic.
    These features are passed as structured context to Gemini.
    """
    tokens = araby.tokenize(sentence)
    word_features = []

    for token in tokens:
        # Strip diacritics for base form
        stripped     = araby.strip_tashkeel(token)
        # Remove only last haraka (useful for case detection)
        no_last      = araby.strip_lastharaka(token)
        # Normalize letter variants (alef, hamza, etc.)
        normalized   = araby.normalize_ligature(araby.normalize_hamza(stripped))
        # Detect definite article
        has_al       = araby.has_alef_lam(stripped) if hasattr(araby, 'has_alef_lam') else stripped.startswith(araby.ALEF + araby.LAM)
        # Sun/moon letter detection for words with Ø§Ù„
        is_sun       = False
        if has_al and len(stripped) > 2:
            is_sun = araby.is_sun(stripped[2])
        # Check if pure Arabic
        is_arabic    = araby.is_arabicrange(token[0]) if token else False

        word_features.append({
            "token"     : token,
            "stripped"  : stripped,
            "normalized": normalized,
            "no_last"   : no_last,
            "has_al"    : has_al,
            "is_sun"    : is_sun,
            "is_arabic" : is_arabic,
        })

    return word_features

def format_features_for_prompt(word_features):
    """
    Format PyArabic features into a readable string for the Gemini prompt.
    """
    lines = []
    for f in word_features:
        al_info = ""
        if f["has_al"]:
            al_info = " | has Ø§Ù„ (definite)" + (" + sun letter assimilation" if f["is_sun"] else " + moon letter")
        lines.append(
            "- " + f["token"] +
            " | base: "       + f["stripped"] +
            " | normalized: " + f["normalized"] +
            al_info
        )
    return "\n".join(lines)

# â”€â”€ Prompt â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
SYSTEM_PROMPT = """Ø£Ù†Øª Ø®Ø¨ÙŠØ± ÙÙŠ Ø§Ù„Ù†Ø­Ùˆ Ø§Ù„Ø¹Ø±Ø¨ÙŠ ÙˆØ§Ù„Ø¥Ø¹Ø±Ø§Ø¨.
You are an expert in Arabic grammar and irab (grammatical analysis).

You will be given an Arabic sentence along with preprocessed linguistic features
extracted by PyArabic (tokenization, normalization, definite article detection,
sun/moon letter classification). Use these features as additional context.

For each word provide:
1. Ø§Ù„Ø¥Ø¹Ø±Ø§Ø¨   â€” grammatical role (ÙØ§Ø¹Ù„ØŒ Ù…ÙØ¹ÙˆÙ„ Ø¨Ù‡ØŒ Ù…Ø¨ØªØ¯Ø£ØŒ Ø®Ø¨Ø±ØŒ ÙØ¹Ù„ Ù…Ø§Ø¶ØŒ Ø­Ø±Ù Ø¬Ø±ØŒ etc.)
2. Ø§Ù„Ø¹Ù„Ø§Ù…Ø©   â€” grammatical marker (Ù…Ø±ÙÙˆØ¹ Ø¨Ø§Ù„Ø¶Ù…Ø©ØŒ Ù…Ù†ØµÙˆØ¨ Ø¨Ø§Ù„ÙØªØ­Ø©ØŒ Ù…Ø¬Ø±ÙˆØ± Ø¨Ø§Ù„ÙƒØ³Ø±Ø©ØŒ Ù…Ø¨Ù†ÙŠØŒ etc.)
3. Ø§Ù„ØªÙØ§ØµÙŠÙ„  â€” details (definiteness, gender, number, verb tense, etc.)
4. explanation â€” one clear sentence in English

Return ONLY a valid JSON array, no markdown, no text outside the array."""

def create_prompt(sentence, word_features):
    features_str = format_features_for_prompt(word_features)
    return (
        SYSTEM_PROMPT
        + "\n\nSentence: " + sentence
        + "\n\nPyArabic linguistic features:\n" + features_str
        + "\n\nReturn ONLY a JSON array:\n"
        + "[{\"word\":\"...\",\"irab\":\"...\",\"sign\":\"...\",\"details\":\"...\",\"explanation\":\"...\"}]"
    )

# â”€â”€ Analysis â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def get_irab(sentence, word_features, client):
    prompt = create_prompt(sentence, word_features)
    for attempt in range(3):
        try:
            response = client.models.generate_content(
                model="gemini-2.0-flash",
                contents=prompt
            )
            text = response.text.strip()
            if text.startswith("```json"):
                text = text.split("```json")[1].split("```")[0].strip()
            elif text.startswith("```"):
                text = text.split("```")[1].split("```")[0].strip()
            return {"success": True, "data": json.loads(text)}
        except json.JSONDecodeError:
            return {"success": False, "error": "Could not parse Gemini response. Try again."}
        except Exception as e:
            err = str(e)
            if "429" in err:
                if "PerDay" in err:
                    return {"success": False, "error": "Daily quota reached. Try again tomorrow."}
                time.sleep(60 * (attempt + 1))
            else:
                return {"success": False, "error": err}
    return {"success": False, "error": "Max retries exceeded."}

@st.cache_data(show_spinner=False)
def run_full_analysis(sentence):
    client        = load_gemini_client()
    word_features = preprocess_arabic(sentence)
    irab_resp     = get_irab(sentence, word_features, client)
    return {
        "original"    : sentence,
        "word_features": word_features,
        "irab"        : irab_resp.get("data", []),
        "success"     : irab_resp["success"],
        "error"       : irab_resp.get("error")
    }

# â”€â”€ UI Helpers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def get_color(irab_type):
    colors = {
        "ÙØ§Ø¹Ù„"      : "#2e7d32",
        "Ù…ÙØ¹ÙˆÙ„ Ø¨Ù‡"  : "#1565c0",
        "Ù…Ø¨ØªØ¯Ø£"     : "#e65100",
        "Ø®Ø¨Ø±"       : "#ad1457",
        "Ù…Ø¶Ø§Ù Ø¥Ù„ÙŠÙ‡" : "#6a1b9a",
        "Ù†Ø¹Øª"       : "#00838f",
        "Ø­Ø§Ù„"       : "#f9a825",
        "ÙØ¹Ù„"       : "#4e342e",
        "Ø­Ø±Ù"       : "#546e7a",
        "Ø¸Ø±Ù"       : "#558b2f",
    }
    for key, color in colors.items():
        if key in irab_type:
            return color
    return "#37474f"

def word_card(word_data):
    color       = get_color(word_data.get("irab", ""))
    word        = word_data.get("word", "")
    irab        = word_data.get("irab", "")
    sign        = word_data.get("sign", "")
    details     = word_data.get("details", "")
    explanation = word_data.get("explanation", "")
    return (
        "<div style=\"background:#fff;border-right:6px solid " + color + ";"
        "border-radius:10px;padding:16px 20px;margin:10px 0;"
        "box-shadow:0 2px 6px rgba(0,0,0,0.08);direction:rtl;\">"
        "<div style=\"font-size:26px;font-weight:bold;color:" + color + ";margin-bottom:8px;\">" + word + "</div>"
        "<p style=\"margin:4px 0\"><strong>Ø§Ù„Ø¥Ø¹Ø±Ø§Ø¨:</strong> " + irab + "</p>"
        "<p style=\"margin:4px 0\"><strong>Ø§Ù„Ø¹Ù„Ø§Ù…Ø©:</strong> " + sign + "</p>"
        "<p style=\"margin:4px 0\"><strong>Ø§Ù„ØªÙØ§ØµÙŠÙ„:</strong> " + details + "</p>"
        "<p style=\"margin:4px 0;color:#666;font-style:italic\">" + explanation + "</p>"
        "</div>"
    )

def render_sidebar():
    with st.sidebar:
        st.markdown("## ğŸ“š Arabic Irab Analyzer")
        st.markdown("### Ù…Ø­Ù„Ù„ Ø§Ù„Ø¥Ø¹Ø±Ø§Ø¨ Ø§Ù„Ø¹Ø±Ø¨ÙŠ")
        st.markdown("---")
        st.markdown("""
        **What this tool does:**
        Paste any Arabic sentence â€” voweled or unvoweled â€”
        and get a full grammatical breakdown of every word.

        **Pipeline:**
        - PyArabic â†’ tokenization, normalization,
          definite article & sun/moon letter detection
        - Gemini 2.0 Flash â†’ full irab analysis
        """)
        st.markdown("---")
        st.markdown("### Ø£Ù…Ø«Ù„Ø© â€” Try an example")
        examples = [
            "Ø°Ù‡Ø¨ Ø§Ù„ÙˆÙ„Ø¯ Ø¥Ù„Ù‰ Ø§Ù„Ù…Ø¯Ø±Ø³Ø©",
            "Ù‚Ø±Ø£ Ø§Ù„Ø·Ø§Ù„Ø¨ Ø§Ù„ÙƒØªØ§Ø¨",
            "ÙƒØªØ¨ Ø§Ù„Ù…Ø¹Ù„Ù… Ø§Ù„Ø¯Ø±Ø³ Ø¹Ù„Ù‰ Ø§Ù„Ø³Ø¨ÙˆØ±Ø©",
            "Ø¬Ø§Ø¡ Ø§Ù„Ø±Ø¬Ù„ Ù…Ù† Ø§Ù„Ø³ÙˆÙ‚",
            "Ø¥Ù† Ø§Ù„Ù„Ù‡ ØºÙÙˆØ± Ø±Ø­ÙŠÙ…",
            "ØªÙØªØ­ Ø§Ù„Ø£Ø²Ù‡Ø§Ø± ÙÙŠ Ø§Ù„Ø±Ø¨ÙŠØ¹",
            "ÙƒØ§Ù† Ø§Ù„Ø·Ù‚Ø³ Ø¬Ù…ÙŠÙ„Ø§Ù‹ ÙÙŠ Ø§Ù„ØµØ¨Ø§Ø­",
        ]
        for ex in examples:
            if st.button(ex, key="ex_" + ex, use_container_width=True):
                st.session_state.input_text = ex
                st.rerun()

# â”€â”€ Main â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def main():
    render_sidebar()

    st.title("ğŸ“š Arabic Irab Analyzer")
    st.markdown(
        "<div style=\"direction:rtl;font-size:22px;color:#555;\">Ù…Ø­Ù„Ù„ Ø§Ù„Ø¥Ø¹Ø±Ø§Ø¨ Ø§Ù„Ø¹Ø±Ø¨ÙŠ</div>",
        unsafe_allow_html=True
    )
    st.markdown("---")

    input_text = st.text_area(
        "Ø£Ø¯Ø®Ù„ Ø§Ù„Ø¬Ù…Ù„Ø© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© â€” Enter Arabic sentence:",
        value=st.session_state.get("input_text", ""),
        height=120,
        placeholder="Ø§ÙƒØªØ¨ Ø¬Ù…Ù„Ø© Ø¹Ø±Ø¨ÙŠØ© Ù‡Ù†Ø§...",
    )

    col1, col2, _ = st.columns([1, 1, 4])
    with col1:
        analyze = st.button("ğŸ” ØªØ­Ù„ÙŠÙ„ | Analyze", type="primary", use_container_width=True)
    with col2:
        if st.button("ğŸ—‘ï¸ Ù…Ø³Ø­ | Clear", use_container_width=True):
            st.session_state.input_text = ""
            st.rerun()

    if analyze and input_text.strip():
        with st.spinner("Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„... | Analyzing..."):
            result = run_full_analysis(input_text.strip())

        if result["success"]:
            st.success("âœ… Analysis complete | Ø§ÙƒØªÙ…Ù„ Ø§Ù„ØªØ­Ù„ÙŠÙ„")

            tab1, tab2, tab3 = st.tabs([
                "ğŸ“Š Ø§Ù„Ø¥Ø¹Ø±Ø§Ø¨ | Irab",
                "ğŸ”¬ Preprocessing | Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©",
                "ğŸ“ Raw Data"
            ])

            with tab1:
                st.markdown("#### Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Ø­ÙˆÙŠ Ø§Ù„ÙƒØ§Ù…Ù„")
                rows = []
                for w in result["irab"]:
                    rows.append({
                        "Ø§Ù„ÙƒÙ„Ù…Ø©"     : w.get("word", ""),
                        "Ø§Ù„Ø¥Ø¹Ø±Ø§Ø¨"    : w.get("irab", ""),
                        "Ø§Ù„Ø¹Ù„Ø§Ù…Ø©"    : w.get("sign", ""),
                        "Ø§Ù„ØªÙØ§ØµÙŠÙ„"   : w.get("details", ""),
                        "Explanation": w.get("explanation", "")
                    })
                st.dataframe(
                    pd.DataFrame(rows),
                    use_container_width=True,
                    hide_index=True
                )
                st.markdown("---")
                st.markdown("#### ØªÙØµÙŠÙ„ ÙƒÙ„ ÙƒÙ„Ù…Ø©")
                for w in result["irab"]:
                    st.markdown(word_card(w), unsafe_allow_html=True)

            with tab2:
                st.markdown("#### PyArabic Preprocessing Features")
                st.markdown("These features were extracted before sending to Gemini:")
                pre_rows = []
                for f in result["word_features"]:
                    pre_rows.append({
                        "Token"      : f["token"],
                        "Base Form"  : f["stripped"],
                        "Normalized" : f["normalized"],
                        "Definite Ø§Ù„": "âœ“" if f["has_al"] else "",
                        "Sun Letter" : "âœ“" if f["is_sun"] else "",
                    })
                st.dataframe(
                    pd.DataFrame(pre_rows),
                    use_container_width=True,
                    hide_index=True
                )

            with tab3:
                st.json(result)

        else:
            st.error("âŒ " + str(result["error"]))

    elif analyze:
        st.warning("âš ï¸ Please enter a sentence first | Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø¥Ø¯Ø®Ø§Ù„ Ø¬Ù…Ù„Ø©")

    st.markdown("---")
    st.markdown(
        "<div style=\"text-align:center;color:#aaa;font-size:13px;\">"
        "Built with PyArabic + Gemini 2.0 Flash Â· Powered by Streamlit"
        "</div>",
        unsafe_allow_html=True
    )

if __name__ == "__main__":
    main()
